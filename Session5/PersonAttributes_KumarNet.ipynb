{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PersonAttrubutes.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/AI_Dataset/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dense, Convolution2D, Conv2D, BatchNormalization, Activation, AveragePooling2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
        "    RandomBrightness, RandomContrast, RandomGamma,\n",
        "    ToFloat, ShiftScaleRotate, Normalize, MotionBlur, Cutout\n",
        ")\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentation = augmentation\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.augmentation is None:\n",
        "            image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        else:\n",
        "            image = np.stack([self.augmentation(image=cv2.imread(item[\"image_path\"]))[\"image\"] for _, item in items.iterrows()])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    HorizontalFlip(p=0.5),\n",
        "    RandomContrast(limit=[0, 0.5], p=0.5),\n",
        "    RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "    RandomBrightness(limit=[0, 0.5], p=0.5),\n",
        "    CLAHE(p=1.0, clip_limit=2.0),\n",
        "    #ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=0, p=0.8), \n",
        "    #ToFloat(max_value=255)\n",
        "    #Cutout(p=1, num_holes=3, max_h_size=40, max_w_size=30)\n",
        "    #MotionBlur(blur_limit=3,p=1)\n",
        "    #Normalize()\n",
        "])\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32, augmentation=AUGMENTATIONS_TRAIN)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=32, shuffle=False, augmentation=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTq24HfSvOjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(train_gen[111][0][0])\n",
        "cv2_imshow(train_gen[103][0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-cqFq2RrJwX"
      },
      "source": [
        "**Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMvD84pUcAU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
        "\n",
        "def get_conv(num_filters=16):\n",
        "    return Conv2D(num_filters, \n",
        "                  kernel_size=3, \n",
        "                  strides=1, \n",
        "                  padding='valid', kernel_initializer=init_pytorch)\n",
        "\n",
        "def my_net(inputs,\n",
        "                 num_classes=10,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = get_conv\n",
        "\n",
        "    x = conv(num_filters=16)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=64)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = MaxPooling2D(2)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=16)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=16)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    #model.add(GlobalAveragePooling2D())\n",
        "    #model.add(Activation('softmax'))\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Activation('relu')(x)\n",
        "    y = GlobalAveragePooling2D()(x)\n",
        "    #y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # heads\n",
        "    gender = build_head(\"gender\", outputs)\n",
        "    image_quality = build_head(\"image_quality\", outputs)\n",
        "    age = build_head(\"age\", outputs, \"sigmoid\")\n",
        "    weight = build_head(\"weight\", outputs)\n",
        "    bag = build_head(\"bag\", outputs)\n",
        "    footwear = build_head(\"footwear\", outputs)\n",
        "    emotion = build_head(\"emotion\", outputs)\n",
        "    pose = build_head(\"pose\", outputs)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion])\n",
        "    return model\n",
        "\n",
        "def build_head(name, in_layer, activation=\"softmax\"):\n",
        "    return Dense(\n",
        "        num_units[name], activation=activation, name=f\"{name}_output\"\n",
        "    )(in_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2iWtKHIrbV4",
        "colab_type": "text"
      },
      "source": [
        "**Model Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_7yCH-rakg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "opt_nesterov = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
        "opt_sgd = SGD(lr=0.003, momentum=0.9)\n",
        "opt_adam = Adam(lr=0.003)\n",
        "\n",
        "model = my_net(Input(shape=(224,224,3)), num_classes=8)\n",
        "losses = {\n",
        "  \"gender_output\": \"binary_crossentropy\",\n",
        "  \"image_quality_output\": \"categorical_crossentropy\",\n",
        "  \"age_output\": \"categorical_crossentropy\",\n",
        "  \"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\",\n",
        "}\n",
        "loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 30, \"pose_output\": 10, \"emotion_output\": 10}\n",
        "#sample_weight_mode = {}\n",
        "model.compile(loss=losses,\n",
        "              loss_weights=loss_weights,\n",
        "              optimizer=opt_nesterov,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7xDk8MVr8LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yahbi-E-vjeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_gender_lr = ReduceLROnPlateau(monitor='val_gender_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_img_quality_lr = ReduceLROnPlateau(monitor='val_image_quality_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_age_lr = ReduceLROnPlateau(monitor='val_age_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_weight_lr = ReduceLROnPlateau(monitor='val_weight_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_bag_lr = ReduceLROnPlateau(monitor='val_bag_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_footwear_lr = ReduceLROnPlateau(monitor='val_footwear_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_pose_lr = ReduceLROnPlateau(monitor='val_pose_output_acc', factor=0.2, patience=3, min_lr=0.001)\n",
        "reduce_emotion_lr = ReduceLROnPlateau(monitor='val_emotion_output_acc', factor=0.2, patience=3, min_lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjQ-WIm1vo8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    class_weight={0: 50., 1: 50., 2: 100., 3: 50., 4: 10., 5: 30., 6: 200., 7: 200.},\n",
        "    callbacks=[reduce_gender_lr,reduce_img_quality_lr,reduce_age_lr,reduce_weight_lr,\n",
        "               reduce_bag_lr,reduce_footwear_lr,reduce_pose_lr,reduce_emotion_lr]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEIBGBvSE44D",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "    class_weight={0: 1., 1: 1., 2: 10., 3: 5., 4: 5., 5: 1., 6: 2., 7: 5.}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j39Nyxr6d-BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqZ3ICz8E-PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}