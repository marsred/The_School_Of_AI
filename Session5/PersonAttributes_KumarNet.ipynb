{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PersonAttrubutes.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/AI_Dataset/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dense, Convolution2D, Conv2D, BatchNormalization, Activation, AveragePooling2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.augmentation is not None:\n",
        "            image = self.augmentation.flow(image, shuffle=False).next()\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "d_augmentation = ImageDataGenerator(\n",
        "      width_shift_range=[-20,20],\n",
        "      height_shift_range=[-20,20],\n",
        "      horizontal_flip=True\n",
        ")\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32, augmentation=None)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=32, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-cqFq2RrJwX"
      },
      "source": [
        "**Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMvD84pUcAU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
        "\n",
        "def get_conv(num_filters=16):\n",
        "    return Conv2D(num_filters, \n",
        "                  kernel_size=3, \n",
        "                  strides=1, \n",
        "                  padding='valid', kernel_initializer=init_pytorch)\n",
        "\n",
        "def my_net(inputs,\n",
        "                 num_classes=10,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "\n",
        "    conv = get_conv\n",
        "\n",
        "    x = conv(num_filters=16)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=64)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = MaxPooling2D(2)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=32)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=16)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    x = conv(num_filters=16)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "\n",
        "    #model.add(GlobalAveragePooling2D())\n",
        "    #model.add(Activation('softmax'))\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Activation('relu')(x)\n",
        "    y = GlobalAveragePooling2D()(x)\n",
        "    #y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # heads\n",
        "    gender = build_head(\"gender\", outputs)\n",
        "    image_quality = build_head(\"image_quality\", outputs)\n",
        "    age = build_head(\"age\", outputs, \"sigmoid\")\n",
        "    weight = build_head(\"weight\", outputs)\n",
        "    bag = build_head(\"bag\", outputs)\n",
        "    footwear = build_head(\"footwear\", outputs)\n",
        "    emotion = build_head(\"emotion\", outputs)\n",
        "    pose = build_head(\"pose\", outputs)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion])\n",
        "    return model\n",
        "\n",
        "def build_head(name, in_layer, activation=\"softmax\"):\n",
        "    return Dense(\n",
        "        num_units[name], activation=activation, name=f\"{name}_output\"\n",
        "    )(in_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2iWtKHIrbV4",
        "colab_type": "text"
      },
      "source": [
        "**Model Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-_7yCH-rakg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "opt_sgd = SGD(lr=0.001, momentum=0.9)\n",
        "opt_adam = Adam(lr=0.003)\n",
        "\n",
        "model = my_net(Input(shape=(224,224,3)), num_classes=8)\n",
        "losses = {\n",
        "  \"gender_output\": \"binary_crossentropy\",\n",
        "  \"image_quality_output\": \"categorical_crossentropy\",\n",
        "  \"age_output\": \"categorical_crossentropy\",\n",
        "  \"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\",\n",
        "}\n",
        "loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 30, \"pose_output\": 10, \"emotion_output\": 10}\n",
        "#sample_weight_mode = {}\n",
        "model.compile(loss=losses,\n",
        "              loss_weights=loss_weights,\n",
        "              optimizer=opt_adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7xDk8MVr8LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEIBGBvSE44D",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
        "    class_weight={0: 1., 1: 1., 2: 10., 3: 5., 4: 5., 5: 1., 6: 2., 7: 5.}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j39Nyxr6d-BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqZ3ICz8E-PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}